1)
!pip install numpy==1.24.3 --upgrade --force-reinstall
!pip install --upgrade genism
from gensim.downloader import load

# Load pre-trained word vectors
word_vectors = load('glove-wiki-gigaword-100')

# Word vector arithmetic
result1 = word_vectors.most_similar(positive=['kitten', 'dog'], negative=['cat'], topn=1)
print("Result of 'kitten - cat + dog':", result1[0][0])

result2 = word_vectors.most_similar(positive=['orange', 'tropical'], negative=['fruit'], topn=1)
print("Result of 'orange - fruit + tropical':", result2[0][0])
----------------------------------
2)
!pip install numpy==1.24.3 --force-reinstall
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from gensim.downloader import load
import numpy as np

word_vectors = load('glove-wiki-gigaword-100')
tech_words = ['computer', 'internet', 'software', 'hardware', 'network', 'data', 'cloud', 'robot', 'algorithm', 'technology']
tech_words = [word for word in tech_words if word in word_vectors.key_to_index]
vectors = np.array([word_vectors[word] for word in tech_words])
tsne = TSNE(n_components=2, random_state=42, perplexity=5)
reduced_vectors = tsne.fit_transform(vectors)
plt.figure(figsize=(10, 6))
for i, word in enumerate(tech_words):
    plt.scatter(reduced_vectors[i, 0], reduced_vectors[i, 1], label=word)
    plt.text(reduced_vectors[i, 0] + 0.02, reduced_vectors[i, 1] + 0.02, word, fontsize=12)
plt.title("t-SNE Visualization of Technology Words")
plt.xlabel("Dimension 1")
plt.ylabel("Dimension 2")
plt.legend()
plt.show()

input_word = 'computer'
if input_word in word_vectors.key_to_index:
    similar_words = word_vectors.most_similar(input_word, topn=5)
    print(f"5 words similar to '{input_word}':")
    for word, similarity in similar_words:
        print(f"{word} (similarity: {similarity:.2f})")
else:
    print(f"'{input_word}' is not in the vocabulary.")
-----------------------------------------------------
3)
!pip install gensim
from gensim.models import Word2Vec

medical_data = [
    ["patient", "doctor", "nurse", "hospital", "treatment"],
    ["cancer", "chemotherapy", "radiation", "surgery", "recovery"],
    ["infection", "antibiotics", "diagnosis", "disease", "virus"],
    ["heart", "disease", "surgery", "cardiology", "recovery"]
]

model = Word2Vec(sentences=medical_data, vector_size=10, window=2, min_count=1, workers=1, epochs=50)

input_word = "patient"
if input_word in model.wv:
    similar_words = model.wv.most_similar(input_word, topn=3)
    print(f"3 words similar to '{input_word}':")
    for word, similarity in similar_words:
        print(f"{word} (similarity: {similarity:.2f})")
else:
    print(f"'{input_word}' is not in the vocabulary.")
-----------------------------------------
4)
word_embeddings = {
    "ai": ["machine learning", "deep learning", "data science"],
    "data": ["information", "dataset", "analytics"],
    "science": ["research", "experiment", "technology"],
    "learning": ["education", "training", "knowledge"],
    "robot": ["automation", "machine", "mechanism"]
}

def find_similar_words(word):
    if word in word_embeddings:
        return word_embeddings[word]
    else:
        return []

def enrich_prompt(prompt):
    words = prompt.lower().split()
    enriched_words = []
    for word in words:
        similar_words = find_similar_words(word)
        if similar_words:
            enriched_words.append(f"{word} ({', '.join(similar_words)})")
        else:
            enriched_words.append(word)
    return " ".join(enriched_words)

original_prompt = "Explain AI and its applications in science."
enriched_prompt = enrich_prompt(original_prompt)
print("Original Prompt:")
print(original_prompt)
print("\nEnriched Prompt:")
print(enriched_prompt)
---------------------------------------------------------------
5)
word_embeddings = {
    "adventure": ["journey", "exploration", "quest"],
    "robot": ["machine", "automation", "mechanism"],
    "forest": ["woods", "jungle", "wilderness"],
    "ocean": ["sea", "waves", "depths"],
    "magic": ["spell", "wizardry", "enchantment"]
}

def get_similar_words(seed_word):
    if seed_word in word_embeddings:
        return word_embeddings[seed_word]
    else:
        return ["No similar words found"]

def create_paragraph(seed_word):
    similar_words = get_similar_words(seed_word)
    if "No similar words found" in similar_words:
        return f"Sorry, I couldn't find similar words for '{seed_word}'."
    paragraph = (
        f"Once upon a time, there was a great {seed_word}. "
        f"It was full of {', '.join(similar_words[:-1])}, and {similar_words[-1]}. "
        f"Everyone who experienced this {seed_word} always remembered it as a remarkable tale."
    )
    return paragraph

seed_word = "adventure"
story = create_paragraph(seed_word)
print("Generated Paragraph:")
print(story)
-----------------------------------------------
8)
!pip install langchain cohere langchain-community
# Step 2: Import the required modules
from langchain.llms import Cohere
from langchain.prompts import PromptTemplate
from langchain import LLMChain
from google.colab import drive
# Step 3: Mount Google Drive to access the document
drive.mount('/content/drive')
# Step 4: Load the text document from Google Drive
file_path = "/content/drive/MyDrive/sample_text.txt" # Change this path to your file location
with open(file_path, "r") as file:
 text = file.read()
# Step 5: Set up Cohere API key
cohere_api_key = "h1PTt2V4cpSh7Z6UDRKXtgs0SkOQvYHkUlaVH1Ea" # Replace with your actual Cohere API key
# Step 6: Create a prompt template
prompt_template = """
Summarize the following text in three bullet points:
{text}
"""
# Step 7: Configure the Cohere model with Langchain
llm = Cohere(cohere_api_key=cohere_api_key)
prompt = PromptTemplate(input_variables=["text"], template=prompt_template)
# Step 8: Create an LLMChain with the Cohere model and prompt template
chain = LLMChain(llm=llm, prompt=prompt)
# Step 9: Run the chain on the loaded text
result = chain.run(text)
# Step 10: Display the formatted output
print("Summarized Output in Bullet Points:")
print(result)



